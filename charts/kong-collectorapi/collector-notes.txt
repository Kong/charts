# Non-agnostic README/NOTES items
* `open` is OS X-only.
* Should not assume Minikube.
* Should not assume open NodePort. We're guilty of this too--we should probably add a port-forward.

# Chart
* Should the bintray-kong-brain-internal regPullSecret be in values.yaml?
* Probably should comment out regPullSecrets by default, since users don't necessarily use our repo.
* Comment default token. Values in the default values.yaml get used if none is otherwise specified, and while harmless, sending "token" by default isn't going to match any actual instance.
* Ditto default static NodePort. They are chose dynamically if not specified.
* Currently the chart attempts to pull `kong-docker-kong-brain-internal-builds.bintray.io/kong-brain-test-endpoints:latest`, which I assume shouldn't be the case for non-internal installations.
* Everything (or at least a lot of things) is currently in its own pod. The Celery pods can presumably be made into containers inside the main collector pod. Redis and Postgres we're kinda stuck with because of how subcharts work.
* Limits/requests should be exposed in values.yaml. They should also exist in the deployments.
* Not sure if there's a way to have an initContainer verify connectivity to Kong. As-is the connector can come up with bad Kong connection settings, and you won't be aware until status (or some other thing) fails.

# Collector
* As of yet no way to disable cert verification when talking to the admin API. This is good in a sense, but we need to note it for testing.

* Setup instructions should be platform-agnostic as best possible. We shouldn't assume Minikube, and should generally assume a production environment if it's not possible to write something fully agnostic. While instructions for test environments are useful (and we need to write them for the Kong chart), we want users to start from a production config and work back to a test config if needed, rather than the reverse. On the support end, it's much easier if users have relatively similar production configurations, or can be pointed to instructions that will get them one.
* We shouldn't assume NodePorts are open, as they generally aren't without intentionally creating firewall rules to open them. This gets a bit tricky since there's probably less reason to expose the collector via an Ingress or LoadBalancer than the Kong services--this and the Kong chart should probably rely on port-forwards to provide access without making other assumptions about the environment.
* We also should not specify a default NodePort in values.yaml--the option should remain, but be commented out, since the default may conflict with a user's environment. K8S defaults to choosing a random available port, which is fine for most scenarios.
* The chart currently tries to pull `kong-docker-kong-brain-internal-builds.bintray.io/kong-brain-test-endpoints:latest`. Is this something that users should have available/is waiting on a public repository, or is it left over from our own internal test setup?
* Is there any reason to separate the Celery containers into separate pods? Does anything need to interact with them other than the Collector, or would we expect to have different scaling requirements for them and the Collector? It looks like they could possibly be moved into a single pod and their services removed.
* values.yaml should expose resource limits/requests.